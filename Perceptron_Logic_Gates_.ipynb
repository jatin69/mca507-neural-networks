{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron - Logic Gates .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jatin69/mca507-neural-networks/blob/master/Perceptron_Logic_Gates_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJofID7RAdAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqIqSYiwBRIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perceptron(object):\n",
        "  \n",
        "  def __init__(self, no_of_inputs = 2, weights = [1, 1], bias = 2):\n",
        "    if(no_of_inputs != len(weights)):\n",
        "      print(\"ERROR : Pass weights of inputs as well in the constructor\")\n",
        "      exit\n",
        "    self.no_of_inputs  = no_of_inputs\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def activation_function(self, inputs):\n",
        "    \"\"\"\n",
        "    Activation function    : Decides whether neuron will activate or not\n",
        "    Internal function used : g(x) : sum of inputs\n",
        "    \"\"\"\n",
        "    willNeuronActivate = 0\n",
        "    sum_of_inputs_with_weights = np.inner(inputs, self.weights)\n",
        "    if sum_of_inputs_with_weights - bias >= 0:\n",
        "      willNeuronActivate = 1\n",
        "    else:\n",
        "      willNeuronActivate\n",
        "    return willNeuronActivate\n",
        "\n",
        "  def draw_truth_table(self):\n",
        "    n = self.no_of_inputs\n",
        "    import itertools\n",
        "    all_possible_combinations = np.array([list(i) for i in itertools.product([0, 1], repeat=n)])\n",
        "    input_labels = [\"x\" + str(i) for i in range(1, n+1)]\n",
        "    output_table = pd.DataFrame(all_possible_combinations, columns = input_labels)\n",
        "    output_label = \"y\"\n",
        "    output_value = []\n",
        "    for current_combination in all_possible_combinations:\n",
        "      willNeuronActivate = self.activation_function(current_combination)\n",
        "      output_value.append(willNeuronActivate)\n",
        "      output_table[output_label] = pd.Series(output_value)\n",
        "    \n",
        "    return output_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwPcvlLlD83G",
        "colab_type": "code",
        "outputId": "78960f09-10fc-4524-8e6f-23d3ac6833f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# AND Gate\n",
        "no_of_inputs = 2; \n",
        "weights = [0.5, 0.5]\n",
        "bias = 1\n",
        "print(Perceptron(no_of_inputs, weights, bias).draw_truth_table())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  0\n",
            "1   0   1  0\n",
            "2   1   0  0\n",
            "3   1   1  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcwTFi-BEAdj",
        "colab_type": "code",
        "outputId": "b58cefa5-33b5-4030-e5c8-cb3be59a10e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# OR Gate\n",
        "no_of_inputs = 2; \n",
        "weights = [1, 1]\n",
        "bias = 1\n",
        "print(Perceptron(no_of_inputs, weights, bias).draw_truth_table())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  0\n",
            "1   0   1  1\n",
            "2   1   0  1\n",
            "3   1   1  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IngQoy0ZEMDj",
        "colab_type": "code",
        "outputId": "3b87e957-7dc3-4522-d189-66da13da74bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# NOT Gate\n",
        "no_of_inputs = 1; \n",
        "weights = [-1]\n",
        "bias = 0\n",
        "print(Perceptron(no_of_inputs, weights, bias).draw_truth_table())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  y\n",
            "0   0  1\n",
            "1   1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVvlJXLwERZK",
        "colab_type": "code",
        "outputId": "e1b709e0-d464-4f2d-ac4f-9fd97a641535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# NAND Gate\n",
        "no_of_inputs = 2; \n",
        "weights = [-1, -1]\n",
        "bias = -1\n",
        "print(Perceptron(no_of_inputs, weights, bias).draw_truth_table())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  1\n",
            "1   0   1  1\n",
            "2   1   0  1\n",
            "3   1   1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbvlxQLCEZvq",
        "colab_type": "code",
        "outputId": "b7466f1a-61d7-43b3-e160-cf4b64fd7081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# NOR Gate\n",
        "no_of_inputs = 2; \n",
        "weights = [-1, -1]\n",
        "bias = -0.5\n",
        "print(Perceptron(no_of_inputs, weights, bias).draw_truth_table())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  1\n",
            "1   0   1  0\n",
            "2   1   0  0\n",
            "3   1   1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hylHtc58EeuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}